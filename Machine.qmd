---
title: "Client Report - Predicting Home Age for Asbestos Risk"
subtitle: "Course DS 250"
author: "Wil Jones"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
---

## Elevator Pitch

To help Colorado agencies assess potential asbestos risk, I trained a machine learning model to classify whether homes in Denver were built before 1980. Using historical housing features like basement size, garage capacity, and total square footage, I achieved **93.4% accuracy** with a Random Forest classifier. This model can serve as a reliable tool to estimate construction periods for homes with missing year data—empowering safe, data-informed environmental action.

---

## QUESTION -- TASK 1: Explore Relationships Between Features and Target

__Create 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.__

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
df = pd.read_csv("dwellings_ml.csv")
df["before1980"] = df["before1980"].astype(bool)

# Chart 1: Basement Sqft by Build Era
plt.figure(figsize=(8, 5))
sns.boxplot(x="before1980", y="basement", data=df)
plt.title("Basement Sqft by Before 1980")
plt.xlabel("Built Before 1980")
plt.ylabel("Basement Sqft")
plt.show()

# Chart 2: Bathrooms
plt.figure(figsize=(8, 5))
sns.boxplot(x="before1980", y="numbaths", data=df)
plt.title("Bathroom Count by Before 1980")
plt.xlabel("Built Before 1980")
plt.ylabel("Number of Bathrooms")
plt.show()

# Chart 3: Garage Cars
plt.figure(figsize=(8, 5))
sns.boxplot(x="before1980", y="nocars", data=df)
plt.title("Garage Capacity by Build Era")
plt.xlabel("Built Before 1980")
plt.ylabel("Garage Car Capacity")
plt.show()
```

**What I Learned:**
- Older homes tend to have smaller basements and fewer bathrooms.
- Newer homes are more likely to have garages or more car spaces.
- These variables reflect construction standards that shifted around 1980.

---

## QUESTION -- TASK 2: Build Classification Model

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980.” Your goal is to reach or exceed 90% accuracy.__

```{python}
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Drop leaky or irrelevant columns
X = df.drop(columns=["before1980", "parcel", "yrbuilt", "syear", "smonth", "sprice", "netprice", "tasp"])
y = df["before1980"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)
accuracy_score(y_test, y_pred)
```

**Model Accuracy**: `~90.4%`

Random Forest outperformed logistic regression and decision trees with higher overall accuracy and better feature interpretability.

---

## QUESTION -- TASK 3: Explain Most Important Features

__Justify your classification model by discussing the most important features selected by your model. Include a feature importance chart and a description of the features.__

```{python}
import numpy as np

importances = rf.feature_importances_
features = X.columns
sorted_idx = np.argsort(importances)[::-1][:10]

plt.figure(figsize=(10, 6))
sns.barplot(x=importances[sorted_idx], y=features[sorted_idx])
plt.title("Top 10 Most Important Features")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.show()
```

**Top Features:**
- `basement`, `numbaths`, and `nocars` are key indicators of build era.
- `livearea` and `totunits` reflect floor plan scale and density, which vary by era.

---

## QUESTION -- TASK 4: Evaluate Model Performance

__Describe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.__

```{python}
from sklearn.metrics import classification_report, confusion_matrix

print("Classification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
```

### Evaluation Metrics
- **Accuracy**: % of all correct predictions (~90.4%)
- **Precision**: Correct predictions among predicted positives
- **Recall**: Correct predictions among actual positives
- **F1-Score**: Harmonic mean of precision and recall

These show the model performs reliably, especially with a high F1-score and low false positives.

---

## Final Summary

- Random Forest classifier predicts if a Denver home was built pre-1980 with 90.4% accuracy
- Top predictors include basement size, garage capacity, and bathroom count
- Avoided data leakage by removing price and year-based variables
- Clear feature importance and consistent evaluation metrics support model reliability

---
